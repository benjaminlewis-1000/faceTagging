More development

# --------------
# Please enter the commit message for your changes. Everything below
# this paragraph is ignored, and an empty message aborts the commit.
# Just close the window to accept your message.
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..c047187
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,2 @@
+*.JPG
+*.pkl
diff --git a/__pycache__/face_extract.cpython-37.pyc b/__pycache__/face_extract.cpython-37.pyc
new file mode 100644
index 0000000..e92447b
Binary files /dev/null and b/__pycache__/face_extract.cpython-37.pyc differ
diff --git a/__pycache__/get_picasa_faces.cpython-37.pyc b/__pycache__/get_picasa_faces.cpython-37.pyc
new file mode 100644
index 0000000..651832f
Binary files /dev/null and b/__pycache__/get_picasa_faces.cpython-37.pyc differ
diff --git a/__pycache__/rectangle.cpython-37.pyc b/__pycache__/rectangle.cpython-37.pyc
new file mode 100644
index 0000000..c445d82
Binary files /dev/null and b/__pycache__/rectangle.cpython-37.pyc differ
diff --git a/__pycache__/tiled_detect.cpython-37.pyc b/__pycache__/tiled_detect.cpython-37.pyc
new file mode 100644
index 0000000..2d6c41f
Binary files /dev/null and b/__pycache__/tiled_detect.cpython-37.pyc differ
diff --git a/face_extract.py b/face_extract.py
index ff9ea4b..7de54b8 100644
--- a/face_extract.py
+++ b/face_extract.py
@@ -11,6 +11,8 @@ import random
 from tiled_detect import detect_pyramid
 import logging
 import xmltodict
+import matplotlib.pyplot as plt
+import get_picasa_faces
 
 coloredlogs.install()
 
@@ -27,16 +29,32 @@ def imageFaceDetect(image_path, parameter_file='parameters.xml'):
 
     tiled_params = parameters['params']['tiled_detect_params']
 
-    npImage = cv2.imread(image_path)
+    npImage = face_recognition.load_image_file(image_path)
+
+    ml_detected_faces = detect_pyramid(npImage, tiled_params)
+
+    success_faces, tagged_faces = get_picasa_faces.Get_XMP_Faces(image_path)
+
+    assert success_faces, 'Picasa face extraction failed.'
+
+    plt.figure()
+    # for f in ml_detected_faces:
+    #     # print(f.enc_dist(ml_detected_faces[1]))
+    #     # print(f.rectangle.intersectOverUnion(ml_detected_faces[0].rectangle))
+    #     for t in tagged_faces:
+    #         print(f.rectangle.intersectOverUnion(t['bounding_rectangle']))
+           
+
+        f.rectangle.drawOnPhoto(npImage)
+
+    for t in tagged_faces:
+        t['bounding_rectangle'].drawOnPhoto(npImage, colorTriple=(255,255,0))
 
-    faceList = detect_pyramid(npImage, tiled_params)
-    print(faceList[0])
-    # print(faceList[0].enc_dist(faceList[1]))
+    # plt.imshow(npImage)
 
-    for f in faceList:
-        print(f.enc_dist(faceList[0]))
+    # plt.show(block=True)
 
-    # return faceList
+    return ml_detected_faces, tagged_faces
     # height, width, channels = npImage.shape
     # print(height)
     # print(width)
diff --git a/get_picasa_faces.py b/get_picasa_faces.py
new file mode 100644
index 0000000..74cc71b
--- /dev/null
+++ b/get_picasa_faces.py
@@ -0,0 +1,216 @@
+#! /usr/bin/env python
+
+# Face tagging test
+
+import os
+import face_recognition
+from PIL import Image
+from time import sleep
+import cv2
+# import pyexiv2
+# from pyPicasaFaceXMP import picasaXMPFaceReader as pfr
+from rectangle import Rectangle as rec
+import re
+import binascii
+import xml
+import xmltodict
+import collections
+from rectangle import Rectangle
+import matplotlib.pyplot as plt
+
+# def toHex(s):
+#     lst = []
+#     for ch in s:
+#         hv = hex(ord(ch)).replace('0x', '')
+#         if len(hv) == 1:
+#             hv = '0'+hv
+#         lst.append(hv)
+    
+#     return reduce(lambda x,y:x+y, lst)
+
+# This function will extract the XMP Bag Tag and Picasa faces
+def Get_XMP_Faces(file):
+    # initialize our return data
+    file_data = None
+    try:
+        # attempt to open the file as binary
+        file_as_binary = open(file,'rb')
+        # if it opened try to read the file
+        file_data = file_as_binary.read()
+        # close the file afterward done
+        file_as_binary.close()
+    except:
+        # if we sell the open the file abort
+        return False, None
+ 
+    # if the file is empty abort
+    if file_data is None:
+        return False, None
+ 
+    # using the file data, attempt to locate the starting XMP XML Bag tag
+    # print(type(file_data))
+
+    # start_string = '<rdf:Bag'
+
+    xmp_start = 0
+    xmp_end = 0
+    bag_tags = []
+    file_data = repr(file_data)
+    while xmp_start > -1:
+        file_data = file_data[xmp_end:]
+        xmp_start = (file_data).find('<rdf:Bag')
+        # also try and locate the ending XMP XML Bag tag
+        xmp_end = (file_data).find('</rdf:Bag') + 10
+        xmp_data = (file_data)[xmp_start:xmp_end ]
+        bag_tags.append(xmp_data)
+
+    persons = []
+    for bag in bag_tags:
+        try:
+            bag_data = xmltodict.parse(bag)
+            if 'rdf:Bag' in bag_data.keys() and 'rdf:li' in bag_data['rdf:Bag'].keys():
+                bag_data = bag_data['rdf:Bag']['rdf:li']
+                # print((bag_data))
+
+                if isinstance(bag_data, collections.OrderedDict):
+                    persons.append(get_person_data(bag_data))
+                elif len(bag_data) and isinstance(bag_data[0], collections.OrderedDict):
+                    for person_num in range(len(bag_data)):
+                        persons.append(get_person_data(bag_data[person_num]))
+
+                def get_person_data(person_dict):
+                    person_data = person_dict['rdf:Description']
+                    assert '@mwg-rs:Name' in person_data.keys()
+                    assert '@mwg-rs:Type' in person_data.keys()
+                    assert 'mwg-rs:Area' in person_data.keys()
+                    name = person_data['@mwg-rs:Name']
+                    assert person_data['@mwg-rs:Type'] == 'Face'
+                    area = person_data['mwg-rs:Area']
+                    area_x = area['@stArea:x']
+                    area_y = area['@stArea:y']
+                    area_w = area['@stArea:w']
+                    area_h = area['@stArea:h']
+                    return {'Name': name, 'Area_x': area_x, 'Area_y': area_y, 'Area_w': area_w, 'Area_h': area_h}
+        except xml.parsers.expat.ExpatError:
+            pass
+
+    # X and Y are locations in the middle of the face. 
+    image = face_recognition.load_image_file(file)
+    img_height, img_width, _ = image.shape
+
+    for p_num in range(len(persons)):
+        left = float(persons[p_num]['Area_x'])
+        top = float(persons[p_num]['Area_y']) 
+        height = float(persons[p_num]['Area_h']) 
+        width = float(persons[p_num]['Area_w'])         
+
+        right = left + width / 2
+        bottom = top + height / 2
+        left = left - width / 2
+        top = top - height / 2
+
+        # print(left, right, top, bottom)
+
+        left = int(left * img_width)
+        right = int(right * img_width)
+        top = int(top * img_height)
+        bottom = int(bottom * img_height)
+
+        height = int(height * img_height)
+        width = int(width * img_width)
+
+        # persons[p_num]['left'] = left
+        # persons[p_num]['right'] = right
+        # persons[p_num]['top'] = top
+        # persons[p_num]['bottom'] = bottom
+        # persons[p_num]['height'] = height
+        # persons[p_num]['width'] = width
+
+        bounding_rectangle = Rectangle(height, width, leftEdge=left, topEdge=top)
+        persons[p_num]['bounding_rectangle'] = bounding_rectangle
+
+        persons[p_num].pop('Area_x')
+        persons[p_num].pop('Area_y')
+        persons[p_num].pop('Area_h')
+        persons[p_num].pop('Area_w')
+
+        cv2.rectangle(image, (left, top), (right, bottom), (255, 0, 0), 5)
+
+    # print(persons)
+    # plt.imshow(image)
+    # plt.show()
+    # print(xmp_start, xmp_end)
+    # if the tag is found, -1 is used and we get "" else we get data
+    # xmp_bag = file_data[xmp_start:xmp_end+len("</rdf:Bag>")]
+ 
+    # if nothing is found abort
+    if len(bag_tags) == 0:
+    # if xmp_bag == "":
+        return False, None
+ 
+    #  if we found something, return tag information
+    return True, persons
+
+'''
+
+train_dir = '/home/benjamin/Desktop/photos_for_test/train'
+test_dir = '/home/benjamin/Desktop/photos_for_test/test'
+
+for root, dirs, files in os.walk(train_dir):
+    for name in files:
+        fullPath = os.path.join(root, name)
+        print fullPath
+
+        metadata = pyexiv2.ImageMetadata(fullPath)
+        metadata.read()
+        picasaMetadata = pfr.Imagedata(fullPath)
+        xmpFaces = pfr.XMPFace(picasaMetadata).getFaces()
+        # print xmpFaces
+
+        # # Load as a numpy array
+        image = face_recognition.load_image_file(fullPath)
+        ocvImage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
+
+        # ocvImage = cv2.resize(ocvImage, (800, 600) )
+        for faces in xmpFaces:
+            personName = faces[4]
+
+            left = faces[0]
+            top = faces[1]
+            width = faces[2]
+            height = faces[3]
+            right = left + width
+            bottom = top + height
+            locRect = rec(left, top, right, bottom)
+
+            cv2.rectangle(ocvImage, (left, top), (right, bottom), (255, 0, 0), 5)
+        # print ocvImage.shape
+
+        # print image.shape
+        ocvImage = cv2.resize(ocvImage, ( ocvImage.shape[1] / 10, ocvImage.shape[0] / 10 ) )
+        print ocvImage.shape
+        face_locations = face_recognition.face_locations(ocvImage, number_of_times_to_upsample=3,  model='cnn')
+        # print face_locations
+
+        for location in face_locations:
+            top, right, bottom, left = location
+            locRect = rec(left, top, right, bottom)
+            face_image = image[top:bottom, left:right]
+            cv2.rectangle(ocvImage, (left, top), (right, bottom), (0, 255, 0), 5)
+            # pil_image = Image.fromarray(face_image)
+            # pil_image.show()
+
+
+
+        # Convert to OpenCV colors, get a resized window, and show image. 
+        cv2.namedWindow('Resized Window', cv2.WINDOW_NORMAL)
+        cv2.resizeWindow('Resized Window', 800, 600)
+        cv2.imshow('Resized Window', ocvImage)
+        cv2.waitKey(0)
+        # sleep(1)
+        # cv2.destroyAllWindows()
+
+            # sleep(0.3)
+            # pil_image.close()
+
+'''
\ No newline at end of file
diff --git a/test_package.py b/test_package.py
index d47dd73..aeb8404 100644
--- a/test_package.py
+++ b/test_package.py
@@ -4,6 +4,7 @@ from rectangle import Rectangle, rectangleError
 import unittest
 from face_extract import imageFaceDetect
 import os
+import get_picasa_faces
 
 path_to_script = os.path.dirname(os.path.realpath(__file__))
 
@@ -36,13 +37,14 @@ class rectangleTester(unittest.TestCase):
 
     def test_iou(self):
         r1 = Rectangle(20, 20, centerX = 30, centerY = 30)
-        r2 = Rectangle(20, 20, centerX = 35, centerY = 35)
+        r2 = Rectangle(20, 20, centerX = 40, centerY = 30)
 
         self.assertNotEqual(r1.intersectOverUnion(r2), 1)
         self.assertNotEqual(r1.intersectOverUnion(r2), 0)
         self.assertEqual(r1.intersectOverUnion(r1), 1)
         self.assertEqual(r2.intersectOverUnion(r2), 1)
 
+
         r1 = Rectangle(20, 20, centerX=10, centerY = 10)
         r2 = Rectangle(20, 20, centerX=20, centerY = 10)
         self.assertEqual(r1.intersectOverUnion(r2), 1/3)
@@ -69,18 +71,45 @@ class rectangleTester(unittest.TestCase):
     #     print(merged)
     #     self.assertEqual(merged, Rectangle(25, 25, leftEdge = 20, topEdge = 20))
 
+import re
+import pickle
+
+
 class FaceExtractTester(unittest.TestCase):
     def setUp(self):
         self.test_photo_dir = os.path.join(path_to_script, 'test_imgs')
         self.photos_list = []
         for root, dirs, files in os.walk(self.test_photo_dir):
             for f in files:
-                self.photos_list.append(os.path.join(root, f))
-
-    def test_one_photo_facedetect(self):
-        # for photo in self.photos_list:
-        print(self.photos_list[2])
-        imageFaceDetect(self.photos_list[2])
+                if f.lower().endswith(('.jpeg', '.jpg')):
+                    self.photos_list.append(os.path.join(root, f))
+
+    # def test_one_photo_facedetect(self):
+    #     # for photo in self.photos_list:
+    #     print(self.photos_list[2])
+    #     ml_faces, tagged_faces = imageFaceDetect(self.photos_list[2])
+
+    def test_extract_and_do_something(self, redo=False):
+        for photo in self.photos_list:
+            out_file = re.sub('.(jpg|JPEG|JPG|jpeg)$', '.pkl', photo)
+            if not os.path.isfile(out_file) or redo:
+                ml_faces, tagged_faces = imageFaceDetect(photo)
+                assert ml_faces is not None
+                assert tagged_faces is not None
+                with open(out_file, 'wb') as fh:
+                    pickle.dump([ml_faces, tagged_faces], fh)
+            else:
+                with open(out_file, 'rb') as fh:
+                    ml_faces, tagged_faces = pickle.load(fh)
+                    # print(ml_faces)
+                    # print(tagged_faces)
+
+    def test_get_xmp(self):
+        for photo in self.photos_list:
+            success, saved_faces = get_picasa_faces.Get_XMP_Faces(photo)
+            self.assertTrue(success)
+
+    # Need to test XMP when image is rotated... 
 
 if __name__ == '__main__':
     unittest.main()
\ No newline at end of file
diff --git a/tiled_detect.py b/tiled_detect.py
index 779e261..e61fdb8 100644
--- a/tiled_detect.py
+++ b/tiled_detect.py
@@ -31,16 +31,24 @@ class FaceRect:
         return 5
 
     def __str__(self):
-        return "rectangle = {}, name = {}, encoding = {}".format(self.rectangle, self.name, self.encoding)
+        return "rectangle = {}, name = {}".\
+            format(self.rectangle, self.name, \
+                self.encoding)
+
+    def __repr__(self):
+        return "rectangle = {}, name = {}".\
+            format(self.rectangle, self.name, \
+                self.encoding)
 
     def enc_dist(self, face):
-        assert isinstance(face, FaceRect), 'encoding distance must be called on another FaceRect object.'
+        assert isinstance(face, FaceRect), \
+          'encoding distance must be called on another FaceRect object.'
         assert self.encoding is not None, 'Encoding on both FaceRect objects must not be none.'
         assert face.encoding is not None, 'Encoding on both FaceRect objects must not be none.'
         assert len(face.encoding) == len(self.encoding), 'Length of both encodings must be equal.'
 
         distance = np.linalg.norm(self.encoding - face.encoding)
-        distance = np.abs(self.encoding - face.encoding)
+        # distance = np.mean(np.abs(self.encoding - face.encoding))
         return distance
 
 
@@ -125,7 +133,7 @@ def detect_pyramid(cv_image, parameters):
                 height_chip = chip_part.shape[0]
                 width_chip = chip_part.shape[1]
                 pixels_here = height_chip * width_chip
-                resize_ratio = np.sqrt( float( pixels_here ) / max_pixels_per_chip ) 
+                resize_ratio = np.sqrt(float(pixels_here) / max_pixels_per_chip)
 
                 resized_chip = cv2.resize(chip_part, \
                     ( int( width_chip / resize_ratio ), \
@@ -133,15 +141,15 @@ def detect_pyramid(cv_image, parameters):
                 # print(resized_chip.shape)
                 face_locations = face_recognition.face_locations(resized_chip, \
                     number_of_times_to_upsample=num_upsamples,  model='cnn')
-                print(face_locations)
+                # print(face_locations)
 
                 identity = face_recognition.face_encodings(resized_chip, known_face_locations=face_locations, num_jitters=3)
 
-                print("ID len: " + str(len(identity)))
+                # print("ID len: " + str(len(identity)))
                 assert len(identity) == len(face_locations), 'Identity vector length != face location vector length.'
 
                 num_faces += len(face_locations)
-                print( num_faces )
+                # print( num_faces )
 
                 for index in range(len(face_locations)):
                     # Get the locations of the face from the
@@ -183,8 +191,8 @@ def detect_pyramid(cv_image, parameters):
                     face = FaceRect(rectangle = face_loc_rect, face_image = face_img, encoding = encoding, name=None)
                     faceList.append(face)
 
-    print(len(faceList))
-    print(len(set(faceList)))
+    # print(len(faceList))
+    # print(len(set(faceList)))
     elapsed_time = time.time() - start_time
     print("Elapsed time is : " + str( elapsed_time ) )